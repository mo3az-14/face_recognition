import torch 
import numpy as np 
import matplotlib.pyplot as plt 
from torch import nn 
import torch.nn.functional as F
from torch.utils.data import DataLoader,Subset
from torchvision import datasets
import torchvision.transforms.v2 as transforms
import torchvision.models as models
import matplotlib.gridspec as gridspec
import torch.cuda.amp as amp
import os
import shutil
import tqdm
# our configurations
import config


rng = np.random.default_rng()








def split_data( src_data_directory : str  , ratio: float  = config.TRAIN_PRECENT ):
    """ Splits the Data into train/test split with train ratio of TRAIN_PRECENT """
     
    names = [ dirs  for root , dirs , files in os.walk(src_data_directory)][0]
    
    rng = np.random.default_rng()
    random_idxs = rng.choice(len(names),len(names), replace = False)
    # make train and test directories
    try: 
        os.mkdir( config.TRAIN_DATASET )
        os.mkdir( config.TEST_DATASET )
    except:
        print("couldn't create train test directories or they already exists")
        
    try : 
        for i in random_idxs[: int ( len(random_idxs)*ratio)]: 
            shutil.move( src_data_directory + '/' + names[i], config.TRAIN_DATASET)
    except: 
        print("train dataset is already split")
    
    try:    
        for i in random_idxs[ int (len(random_idxs)*ratio):  ]:
            shutil.move( src_data_directory + '/' + names[i], config.TEST_DATASET)
    except:
        print("test dataset is already split")

    print(int ( np.floor(len(random_idxs)*ratio)) - int ( np.ceil(len(random_idxs)*ratio)))
    # remove the rest of the files 
    for ( root,dirs,files) in os.walk(src_data_directory):
        for f in files:
            os.remove(src_data_directory+"/"+f)
            
    os.rmdir(src_data_directory)


def uncompress_data(tgz_file_path:str , dst: str ):
    """uncompress the given file tgz file and removes the .tgz file"""
    import tarfile
    file = tarfile.open(tgz_file_path)
    file.extractall(dst)
    file.close()
    os.remove(tgz_file_path)  


#!pip install kaggle
if not os.path.exists(config.DATASET): 
    print("Didn't find a \"dataset\" folder... \ndownloading the dataset from kaggle. Please provide your kaggle username and\
 api key to download")
    
    # setup enviroment and download the dataset 
    os.environ["KAGGLE_USERNAME"] = config.KAGGLE_USERNAME
    os.environ["KAGGLE_KEY"] = config.KAGGLE_KEY
    import kaggle
    kaggle.api.authenticate()
    kaggle.api.dataset_download_files('atulanandjha/lfwpeople', path=config.DATASET, unzip=True)

    # files we won't need
    os.remove("dataset/pairsDevTrain.txt")
    os.remove("dataset/pairsDevTest.txt")
    os.remove("dataset/pairs.txt")
    
    uncompress_data(config.DATASET+"/lfw-funneled.tgz" , config.DATASET)
    split_data(src_data_directory=config.DATASET+"/lfw_funneled")

else:
    print("found the \"dataset\" folder")


_ , train_dirs , _ = next(os.walk(config.TRAIN_DATASET))
train_dirs = len(train_dirs)
train_files_less= 0
train_files_total= 0
for root , dirs , files in os.walk(config.TRAIN_DATASET):
    if (root == config.TRAIN_DATASET): 
        pass 
    train_files_total+=1
    if len(files)<2 :
        train_files_less += 1
print(f"percentage of training folders with less than 2 examples {train_files_less*100/train_files_total :2f}%")


_ , test_dirs , _ = next(os.walk(config.TEST_DATASET))
test_dirs = len(test_dirs)
test_files_less= 0
test_files_total= 0
for root , dirs , files in os.walk(config.TEST_DATASET):
    if (root == config.TEST_DATASET): 
        pass 
    test_files_total+=1
    if len(files)<2 :
        test_files_less += 1
print(f"percentage of testing folders with less than 2 examples {test_files_less*100/test_files_total :2f}%")











class Pair_Data_Loader(datasets.ImageFolder) :
    def __init__(self,indices=None, *arg, **kw):
        super( Pair_Data_Loader, self).__init__(*arg,**kw)
        if indices is not None:
            self.samples= [self.samples[i] for i in indices]
            self.targets= [self.targets[i] for i in indices]
        self.n_pairs= len(self.samples)
        self.train_pairs= self.gen_example()
    def __len__(self): 
        return (len(self.targets))

    def gen_example(self): 
        labels= torch.Tensor(self.targets) 
        positive = [] 
        negative = []
        for x in range(len(labels)): 
            idx = x
            idx_matches = np.where(labels.numpy() == labels[idx].numpy())[0]
            idx_no_matches = np.where(labels.numpy()!= labels[idx].numpy())[0]
            idx_1 = np.random.choice(idx_matches , 2, replace = True )
            idx_0 = np.random.choice(idx_no_matches , 1 , replace = True )
            positive.append([idx_1[0] , idx_1[1], 1  ])
            negative.append([idx_0[0] , idx_1[0], 0 ])
        result = np.vstack((positive, negative ))
        rng.shuffle(result)
        return result 

    def get_mean_std(self): 
        mean , std , size = 0.0 , 0.0 , 0 
        for x , _ in self.samples: 
            size +=1 
            print(self.loader(x).mean())
    
            
    def set_pairs(self , pairs ): 
        self.train_pairs = pairs

    
    def __getitem__(self, idx):
        t = self.train_pairs[idx]        
        path_pos, _ = self.samples[t[0]]
        path_neg, _ = self.samples[t[1]]
        img_pos = self.loader(path_pos)
        img_neg = self.loader(path_neg)
        if self.transform is not None:
            img_pos = self.transform(img_pos)
            img_neg = self.transform(img_neg)     
        target = torch.tensor(t[2] , dtype = torch.float32)
        return img_pos , img_neg , target


data_transform= data_transform = transforms.Compose([
            transforms.ToImage(),
            transforms.ToDtype(torch.float32, scale=True),
            transforms.Resize(size=config.IMAGE_SIZE ),
            # transforms.RandomPerspective(distortion_scale=0.6, p=0.7),
            # transforms.RandomRotation(degrees=(0, 90) ),
            # transforms.RandomHorizontalFlip(p=0.4)
        ])

pair_data_train =Pair_Data_Loader( root=config.TRAIN_DATASET, transform=data_transform )
pair_dataloader_train  = DataLoader(pair_data_train, batch_size=64, shuffle=False , pin_memory = True )

pair_data_test =Pair_Data_Loader( root=config.TEST_DATASET, transform=data_transform  )
pair_dataloader_test = DataLoader(pair_data_test, batch_size=64, shuffle=False, pin_memory= True  )





torch


tup1 , tup2 , target = next(iter(pair_dataloader_train))
fig, axes = plt.subplots(10, 2, figsize=(10, 20)) 

for i ,  batch in enumerate( pair_dataloader_train ):
    
    for y  in range(batch[0].shape[0]):         
        
        img1 = batch[0][y]
        img2 = batch[1][y]
        target = batch[2][y]
        print(img1)

        axes[y][0].title.set_text(target)
        axes[y][0].imshow(img1.permute(1,2,0).numpy(), aspect='auto')
        axes[y][0].axis('off')

        axes[y][1].imshow(img2.permute(1,2,0).numpy(), aspect='auto')
        axes[y][1].axis('off')
        if y == 9:
            break
    break 
plt.show()


class Triplet_Data_Loader(datasets.ImageFolder):
    def __init__(self,indices=None, *arg, **kw) :
        super(Triplet_Data_Loader, self).__init__(*arg, **kw)
        if indices is not None:
            self.samples = [self.samples[i] for i in indices]
            self.targets = [self.targets[i] for i in indices]
        self.n_triplets =len(self.samples)
        self.train_triplets = self.gen_example()
        
    def __len__(self):
        return (len(self.targets))

    def gen_example(self ): 
       labels = torch.Tensor(self.targets)
       triplets = []
       for x in np.arange(self.n_triplets): 
            idx = np.random.randint(0, labels.size(0))
            idx_matches = np.where(labels.numpy() == labels[idx].numpy())[0] 
            idx_no_matches = np.where(labels.numpy() != labels[idx].numpy())[0]
            idx_a, idx_p = np.random.choice(idx_matches, 2, replace=True)
            idx_n = np.random.choice(idx_no_matches, 1)[0]
            triplets.append([  idx_a,idx_p, idx_n])
            
       return np.array(triplets)
    
    def set_triplets(self, triplets):
        self.train_triplets = triplets
    


    def __getitem__(self, idx):
        t = self.train_triplets[idx]
        path_a, _ = self.samples[t[0]]
        path_p, _ = self.samples[t[1]]
        path_n, _ = self.samples[t[2]]

        img_a = self.loader(path_a)
        img_p = self.loader(path_p)
        img_n = self.loader(path_n)
        if self.transform is not None:
            img_a = self.transform(img_a)
            img_p = self.transform(img_p)
            img_n = self.transform(img_n)
        
        
        return img_p , img_a , img_n


data_transform= data_transform = transforms.Compose([
            transforms.ToImage(),
            transforms.ToDtype(torch.float32, scale=True),
            transforms.Resize(size=config.IMAGE_SIZE ),
            # transforms.RandomPerspective(distortion_scale=0.6, p=0.7),
            # transforms.RandomRotation(degrees=(0, 90) ),
            # transforms.RandomHorizontalFlip(p=0.4)
        ])

triplet_data_train =Triplet_Data_Loader( root=config.TRAIN_DATASET, transform=data_transform  , indices = np.arange(100)  )
triplet_dataloader_train  = DataLoader(triplet_data_train, batch_size=512, shuffle=False , pin_memory = True )

triplet_data_test =Triplet_Data_Loader( root=config.TEST_DATASET, transform=data_transform ,indices=np.arange(100) )
triplet_dataloader_test = DataLoader(triplet_data_test, batch_size=512, shuffle=False , pin_memory= True  )





# siamese network
# setup training device
device = "cuda" if torch.cuda.is_available() else "cpu"

class Model(nn.Module): 
    def __init__(self ): 
        """ 
        model input shape is (batch size , CH, W , H) 
        """
        super().__init__()
        # backbone model
        self.conv1 = nn.Conv2d(3,64,10) 
        self.conv2 = nn.Conv2d(64,128,7) 
        self.conv3 = nn.Conv2d(128,128,4) 
        self.conv4 = nn.Conv2d(128,256,4) 
        
        self.fc1 = nn.Linear(256*8*8,4096 )
        self.fc2 = nn.Linear(4096,1 )
    def step(self , x ):
        x= F.relu(self.conv1(x))
        x= F.max_pool2d(x,2)
        x= F.relu(self.conv2(x))
        x= F.max_pool2d(x, 2)
        x= F.relu(self.conv3(x))
        x= F.max_pool2d(x, 2)
        x= F.relu(self.conv4(x))
        x= x.view(x.size()[0], -1)
        x= self.fc1(x)
        x= F.sigmoid(x)
        return x
        
    def forward (self , x1, x2):
        img1 = self.step(x1)
        img2 = self.step(x2)
        l1 = torch.abs(img1 - img2)
        output = self.fc2(l1)
        return output


model = Model().cuda()
optimizer = torch.optim.Adam(params=model.parameters(), lr=0.005, weight_decay=0.1)
loss_function = nn.BCEWithLogitsLoss()
scaler = amp.GradScaler()


def train_step(model: torch.nn.Module,
               train_data ,
               test_data,
               loss_fn,
               optimizer,
               device: torch.device = device ,
               epochs : int = 100):
    train_loss_acc = []
    test_loss_acc= []
    for i in range(epochs):
       
        train_loss, train_acc = 0, 0
        test_loss, test_acc =0,0
        model.train()

        for batch, (first , second , target ) in enumerate(tqdm.tqdm(train_data)):
            
            optimizer.zero_grad()

            first , second , target = first.to(device , non_blocking=True ),second.to(device,non_blocking=True),target.to(device, dtype = torch.float32,non_blocking=True)
            
            with amp.autocast():
                output = model(first , second)
                output = output.squeeze() 
                loss = loss_fn (output , target )
            
            scaler.scale(loss).backward()
            
            scaler.step(optimizer)
            
            scaler.update()
            
            train_loss+= loss
        
        train_loss_acc.append(train_loss)
        
        with torch.no_grad() : 
            model.eval()
            for batch, (first , second , target ) in enumerate(tqdm.tqdm(test_data)):
                
                first , second , target = first.to(device , non_blocking=True ),second.to(device,non_blocking=True),target.to(device,non_blocking=True)
                
                output = model(first , second)

                output = output.squeeze() 
                
                loss = loss_fn (output , target.type(torch.float32))
                
                test_loss += loss

            test_loss_acc.append(test_loss)
        print(f"train loss: {train_loss:.4f} test loss: {test_loss:.4f}@ epoch {i}")
    return train_loss_acc , test_loss_acc


train_loss , test_loss = train_step(model, pair_dataloader_train , pair_dataloader_test, loss_function, optimizer,  device , epochs= 5)


# our loss calculation class 
class loss_fn(): 
    def __init__(self, margin , model):
        
        self.margin = torch.tensor(margin).to(device)
        self.model = model
        
    def _embedding(self,inputs : list[torch.tensor]):
        """
        inputs : list[torch.tensor] with the shape (positive, anchor, negative)
        output : list[torch.tensor] with the shape (positive, anchor, negative)
        """
        # [3,3,256,256]
        
        positive = self.model(inputs[0])
        anchor = self.model(inputs[1])
        negative = self.model(inputs[2])

        return [positive,anchor,negative]
        
    def compute_distance(self, inputs):

        embeddings = self._embedding(inputs)
        
        positiveEmbedding = embeddings[0]
        anchorEmbedding = embeddings[1]
        negativeEmbedding = embeddings[2]
        
        # calculate the anchor to positive and negative distance 
        apDistance = torch.sum( torch.square(anchorEmbedding - positiveEmbedding) , axis =1 )
        anDistance = torch.sum( torch.square(anchorEmbedding - negativeEmbedding), axis=1 )
        
        return apDistance , anDistance
    
    def compute_loss(self , apDistance , anDistance):
        # return the distances
        loss = apDistance - anDistance
        loss = torch.max(loss + self.margin, torch.tensor(0.0).to(device))
        
        return loss
