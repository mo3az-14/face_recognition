{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e8c55d-08c8-483a-9203-e4ec094ced31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 \n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512ad5f3-5df0-4a73-8385-72e4266fdfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\moaaz/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "# setup training device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# get efficientnet-b0 as a backbone\n",
    "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
    " \n",
    "# delete the last classifier layer\n",
    "efficientnet.classifier.fc= nn.Identity()\n",
    "\n",
    "# freeze all parameters for efficientnet-b0\n",
    "for param in efficientnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# putting model on device \n",
    "efficientnet= efficientnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "941c3da3-98a7-40bb-bbff-3c3d0d24b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese network\n",
    "class Model(nn.Module): \n",
    "    def __init__(self  ): \n",
    "        \"\"\" \n",
    "        model input shape is (batch size , CH, W , H) \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.pool = nn.Sequential( \n",
    "            nn.AvgPool1d(kernel_size = 3, stride=2 , padding=1)\n",
    "        )\n",
    "        self.f1 = nn.Sequential( \n",
    "            nn.Linear(in_features=640, out_features=1024 ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2 ),\n",
    "            nn.BatchNorm1d(num_features=1024)\n",
    "        ) \n",
    "        self.f2 = nn.Sequential( \n",
    "            nn.Linear(in_features=1024, out_features=512 ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2 ),\n",
    "            nn.BatchNorm1d(num_features=512)\n",
    "        )\n",
    "        self.f3= nn.Sequential( \n",
    "            nn.Linear(in_features=512, out_features=256 ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2 ),\n",
    "            nn.BatchNorm1d(num_features=256))\n",
    "        self.embed= nn.Sequential( \n",
    "            nn.Linear(in_features=256, out_features=128 ),\n",
    "        ) \n",
    "    def forward (self , x ):\n",
    "        x= efficientnet(x)\n",
    "        x=self.pool(x)\n",
    "        x= self.f1(x)\n",
    "        x= self.f2(x)\n",
    "        x= self.f3(x)\n",
    "        x= self.embed(x)\n",
    "        return x\n",
    "        \n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d99050a2-efa3-4e6f-9cc8-9519829e366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our loss calculation class \n",
    "class loss_fn(): \n",
    "    def __init__(self, margin , model):\n",
    "        \n",
    "        self.margin = torch.tensor(margin).to(device)\n",
    "        self.model = model\n",
    "        \n",
    "    def _embedding(self,inputs : list[torch.tensor]):\n",
    "        \"\"\"\n",
    "        inputs : list[torch.tensor] with the shape (positive, anchor, negative)\n",
    "        output : list[torch.tensor] with the shape (positive, anchor, negative)\n",
    "        \"\"\"\n",
    "        print(inputs.shape)\n",
    "        \n",
    "        positive, anchor ,negative = self.model(inputs)\n",
    "\n",
    "        return [positive,anchor,negative]\n",
    "        \n",
    "    def compute_distance(self, inputs):\n",
    "\n",
    "        embeddings = self._embedding(inputs)\n",
    "        \n",
    "        anchorEmbedding = embeddings[1]\n",
    "        positiveEmbedding = embeddings[0]\n",
    "        negativeEmbedding = embeddings[2]\n",
    "        # calculate the anchor to positive and negative distance\n",
    "        apDistance = torch.sum( torch.square(anchorEmbedding - positiveEmbedding), axis=-1)\n",
    "        anDistance = torch.sum( torch.square(anchorEmbedding - negativeEmbedding), axis=-1 )\n",
    "        \n",
    "        # return the distances\n",
    "        return (apDistance, anDistance)\n",
    "    \n",
    "    def compute_loss(self, apDistance, anDistance):\n",
    "        loss = apDistance - anDistance\n",
    "        loss = torch.max(loss + self.margin, torch.tensor(0.0).to(device))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c07f72-0e0e-4b24-97fc-8f1e46223c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "[40 , (3,3,256,256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d39935b2-2ccd-4cbb-865e-588ec2740184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data ,\n",
    "               loss_fn,\n",
    "               optimizer,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch,inputs in enumerate(data):\n",
    "\n",
    "        # Send data to GPU\n",
    "        # postive , anchor , negative = postive.to(device), anchor.to(device), negative.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "        apDistance, anDistance = loss_fn.compute_distance(inputs)\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn.compute_loss(apDistance, anDistance )\n",
    "        train_loss += loss\n",
    "        # train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    # train_loss /= len(data_loader)\n",
    "    # train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19f165ec-8b08-499a-9704-71fba6cfdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8134a3ee-b53f-4563-9b93-04a973383fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample \n",
    "sample = torch.randn((3,3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a8a76632-2adc-4d9e-afc0-ca0b397df553",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = loss_fn(0.1 , model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "84a3e899-3ae0-4b60-b553-8ebe1e87c0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 256, 256])\n",
      "Train loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "train_step(model, [sample], loss_function, optimizer,  device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9ef77-c348-4218-95ee-159968f9c7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca679682-da6e-471e-a286-c3fb6a8052da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
