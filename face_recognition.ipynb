{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "a7e8c55d-08c8-483a-9203-e4ec094ced31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from torch import nn \n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "49fa1528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "512ad5f3-5df0-4a73-8385-72e4266fdfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\moaaz/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "# setup training device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# get efficientnet-b0 as a backbone\n",
    "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
    "\n",
    "# delete the last classifier layer\n",
    "efficientnet.classifier.fc= nn.Identity()\n",
    "\n",
    "# freeze all parameters for efficientnet-b0\n",
    "for param in efficientnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# putting model on device \n",
    "efficientnet= efficientnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "941c3da3-98a7-40bb-bbff-3c3d0d24b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese network\n",
    "class Model(nn.Module): \n",
    "    def __init__(self  ): \n",
    "        \"\"\" \n",
    "        model input shape is (batch size , CH, W , H) \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.pool = nn.Sequential( \n",
    "            nn.AvgPool1d(kernel_size = 3, stride=2 , padding=1)\n",
    "        )\n",
    "        self.f1 = nn.Sequential( \n",
    "            nn.Linear(in_features=640, out_features=1024 ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2 ),\n",
    "            nn.BatchNorm1d(num_features=1024)\n",
    "        ) \n",
    "        self.f2 = nn.Sequential( \n",
    "            nn.Linear(in_features=1024, out_features=512 ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2 ),\n",
    "            nn.BatchNorm1d(num_features=512)\n",
    "        )\n",
    "        self.f3= nn.Sequential( \n",
    "            nn.Linear(in_features=512, out_features=256 ),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2 ),\n",
    "            nn.BatchNorm1d(num_features=256))\n",
    "        self.embed= nn.Sequential( \n",
    "            nn.Linear(in_features=256, out_features=128 ),\n",
    "        ) \n",
    "    def forward (self , x ):\n",
    "        x= efficientnet(x)\n",
    "        x=self.pool(x)\n",
    "        x= self.f1(x)\n",
    "        x= self.f2(x)\n",
    "        x= self.f3(x)\n",
    "        x= self.embed(x)\n",
    "        return x\n",
    "        \n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "d99050a2-efa3-4e6f-9cc8-9519829e366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our loss calculation class \n",
    "class loss_fn(): \n",
    "    def __init__(self, margin , model):\n",
    "        \n",
    "        self.margin = torch.tensor(margin).to(device)\n",
    "        self.model = model\n",
    "        \n",
    "    def _embedding(self,inputs : list[torch.tensor]):\n",
    "        \"\"\"\n",
    "        inputs : list[torch.tensor] with the shape (positive, anchor, negative)\n",
    "        output : list[torch.tensor] with the shape (positive, anchor, negative)\n",
    "        \"\"\"\n",
    "        # [3,3,256,256]\n",
    "        positive = self.model(inputs[0])\n",
    "        anchor = self.model(inputs[1])\n",
    "        negative = self.model(inputs[2])\n",
    "\n",
    "        return [positive,anchor,negative]\n",
    "        \n",
    "    def compute_distance(self, inputs):\n",
    "\n",
    "        embeddings = self._embedding(inputs)\n",
    "        \n",
    "        anchorEmbedding = embeddings[1]\n",
    "        positiveEmbedding = embeddings[0]\n",
    "        negativeEmbedding = embeddings[2]\n",
    "    \n",
    "        # calculate the anchor to positive and negative distance\n",
    "        apDistance = torch.sum( torch.square(anchorEmbedding - positiveEmbedding), axis=-1)\n",
    "        anDistance = torch.sum( torch.square(anchorEmbedding - negativeEmbedding), axis=-1 )\n",
    "        return apDistance , anDistance\n",
    "    \n",
    "    def compute_loss(self , apDistance , anDistance):\n",
    "        # return the distances\n",
    "        loss = apDistance - anDistance\n",
    "        loss = torch.max(loss + self.margin, torch.tensor(0.0).to(device))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "19f165ec-8b08-499a-9704-71fba6cfdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "a8a76632-2adc-4d9e-afc0-ca0b397df553",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = loss_fn(0.5, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c234f",
   "metadata": {},
   "source": [
    "# Data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "f55faffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_data_loader(datasets.ImageFolder):\n",
    "    def __init__(self, *arg, **kw) :\n",
    "        super(custom_data_loader, self).__init__(*arg, **kw)\n",
    "        self.n_triplets =len(self.samples)\n",
    "        \n",
    "        self.train_triplets = self.gen_example()\n",
    "    def __len__(self):\n",
    "        return (len(self.targets))\n",
    "\n",
    "    def gen_example(self ): \n",
    "       \n",
    "       labels = torch.Tensor(self.targets)\n",
    "    \n",
    "       triplets = []\n",
    "       for x in np.arange(self.n_triplets): \n",
    "            \n",
    "            idx = np.random.randint(0, labels.size(0))\n",
    "            idx_matches = np.where(labels.numpy() == labels[idx].numpy())[0] \n",
    "            idx_no_matches = np.where(labels.numpy() != labels[idx].numpy())[0]\n",
    "            idx_a, idx_p = np.random.choice(idx_matches, 2, replace=True)\n",
    "            idx_n = np.random.choice(idx_no_matches, 1)[0]\n",
    "            triplets.append([  idx_a,idx_p, idx_n])\n",
    "       return np.array(triplets)\n",
    "    \n",
    "    def set_triplets(self, triplets):\n",
    "        self.train_triplets = triplets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = self.train_triplets[idx]\n",
    "\n",
    "        path_a, _ = self.samples[t[0]]\n",
    "        path_p, _ = self.samples[t[1]]\n",
    "        path_n, _ = self.samples[t[2]]\n",
    "\n",
    "        img_a = self.loader(path_a)\n",
    "        img_p = self.loader(path_p)\n",
    "        img_n = self.loader(path_n)\n",
    "        if self.transform is not None:\n",
    "            img_a = self.transform(img_a)\n",
    "            img_p = self.transform(img_p)\n",
    "            img_n = self.transform(img_n)\n",
    "        \n",
    "        return img_p , img_a , img_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "63bed995",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform= data_transform = transforms.Compose([\n",
    "            transforms.Resize(size=config.IMAGE_SIZE ),\n",
    "            transforms.ToTensor() \n",
    "        ])\n",
    "triplet_data_train  =custom_data_loader( root=config.TRAIN_DATASET, transform=data_transform  )\n",
    "triplet_dataloader_train  = DataLoader(triplet_data_train, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "ea3fcdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_data_test  =custom_data_loader( root=config.TEST_DATASET, transform=data_transform  )\n",
    "triplet_dataloader_test  = DataLoader(triplet_data_test, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "d39935b2-2ccd-4cbb-865e-588ec2740184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               train_data ,\n",
    "               test_data,\n",
    "               loss_fn,\n",
    "               optimizer,\n",
    "               device: torch.device = device ,\n",
    "               epochs : int = 10):\n",
    "    train_loss_acc = []\n",
    "    test_loss_acc= []\n",
    "    for i in range(epochs):\n",
    "       \n",
    "        train_loss, train_acc = 0, 0\n",
    "        test_loss, test_acc =0,0\n",
    "        for batch, (p , a,n ) in enumerate(train_data):\n",
    "        # Send data to GPU\n",
    "        # postive , anchor , negative = postive.to(device), anchor.to(device), negative.to(device)\n",
    "            p ,a ,n = p.to(device),a.to(device),n.to(device)\n",
    "            inputs = torch.stack([p,a,n] , dim =0)\n",
    "        # 2. Calculate loss\n",
    "            \n",
    "            apDistance , anDistance = loss_fn.compute_distance(inputs)\n",
    "            loss = loss_fn.compute_loss(apDistance , anDistance  )\n",
    "\n",
    "            train_loss += loss.sum()\n",
    "        # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "        # 4. Loss backward\n",
    "            loss.sum().backward()\n",
    "        # 5. Optimizer step\n",
    "            optimizer.step() \n",
    "        train_loss_acc.append(train_loss.detach().to(\"cpu\").numpy())\n",
    "        model.eval()\n",
    "        with torch.no_grad() : \n",
    "            for batch, (p , a,n ) in enumerate(test_data):\n",
    "        \n",
    "        # Send data to GPU\n",
    "        # postive , anchor , negative = postive.to(device), anchor.to(device), negative.to(device)\n",
    "                p ,a ,n = p.to(device),a.to(device),n.to(device)\n",
    "                inputs = torch.stack([p,a,n] , dim =0)\n",
    "        # 2. Calculate loss\n",
    "            \n",
    "                apDistance , anDistance = loss_fn.compute_distance(inputs)\n",
    "                loss = loss_fn.compute_loss(apDistance , anDistance  )\n",
    " \n",
    "                test_loss += loss.sum()\n",
    "\n",
    "            test_loss_acc.append(test_loss.to(\"cpu\").detach().numpy())\n",
    "        print(f\"train loss: {train_loss} test loss: {test_loss} @ epoch {i}\")\n",
    "    return train_loss_acc , test_loss_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a779c68b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loss , test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m(model, triplet_dataloader_train , triplet_dataloader_test, loss_function, optimizer,  device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_step' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss , test_loss = train_step(model, triplet_dataloader_train , triplet_dataloader_test, loss_function, optimizer,  device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a5c51",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- get a better model\n",
    "- evaluation metrics\n",
    "- setup testing on a single input  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
